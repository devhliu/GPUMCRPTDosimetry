High-level review

The physics design is solid: you‚Äôve clearly separated Domain A (decay/source term) from Domain B (transport) and you‚Äôve written down the key ‚Äúno double counting / energy conservation‚Äù rules (neutrinos ignored, annihilation handled in transport, cutoff deposits remaining 
ùê∏
ùëò
E 
k
‚Äã
 , relaxation energy conserved).
The GPU architecture direction is also solid and modern: SoA banks + wavefront, atomic appends, GPU compaction, Philox RNG, and the planned bucketed CUDA graphs are exactly the right building blocks for the performance target you wrote in the docs.
Biggest immediate issues (code/package consistency)

There are several ‚Äúwiring completeness‚Äù problems that will block users from running the package end-to-end:
load_physics_tables_h5() in tables.py constructs tables but never returns it.
run_dosimetry() in pipeline.py saves dose but never saves uncertainty (even though it computes unc).
pipeline.py and tests refer to modules that are not present in this package tree (e.g. gpumcrpt.materials.hu_materials, gpumcrpt.io.nifti, gpumcrpt.dose.scoring). That suggests either missing files or stale imports.
configs/example_simulation.yaml is only 13 lines and doesn‚Äôt contain required config blocks that pipeline.py expects (io, materials, physics_tables, decaydb, nuclide, cutoffs, etc.).
Physics correctness suggestions (highest value)

Fix source sampling semantics in sampling.py:
Right now it adds energies across emission categories into one photon/electron per history (photons_E = gamma_E + xray_E, similarly for electrons). That is not physically correct (multiple emissions should create multiple particles, not one particle with summed energy).
Directions are shared across categories per history; each emitted particle should be isotropic independently (or at least sampled per particle created).
If you want to keep ‚Äú‚â§1 line per category per history‚Äù for performance, the correct way is usually weighted splitting: sample at most one emission, but scale particle weight by expected multiplicity/yield so the estimator stays unbiased (and don‚Äôt sum energies).
Atomic relaxation ‚Äúeffective Z per material‚Äù is a good MVP, but it‚Äôs a known approximation:
Next step is to move from an ‚Äúeffective Z‚Äù to elemental fractions per material class (even a small set: H/C/N/O/Ca/P for tissue/bone) so shell probabilities and binding energies are more faithful.
Add explicit energy bookkeeping validation gates (you already describe them in docs):
Per-batch: (sum(edep) + escaped_energy) vs sum(source_energy - neutrinos) within tolerance.
Interaction-specific checks: Compton doesn‚Äôt locally deposit recoil energy if recoil electron is created; pair doesn‚Äôt locally deposit 1.022 MeV; brems/Œ¥ subtract emitted energy from parent.
GPU performance/architecture suggestions

Pick one ‚Äúcurrent engine‚Äù and integrate phases into a single production path:
Right now there are many phase modules (engine_gpu_triton_phase10_*, phase11_*, bucketed graphs engine) but TransportEngine still routes batches through a placeholder-ish engine and the bucketed graphs object is instantiated but not used.
Recommendation: choose Phase 11 ‚Äúone sync per step‚Äù (it‚Äôs a pragmatic compromise) and make it the default engine, then keep the fully GPU-resident variant behind a flag.
Reduce allocations in the hot loop:
In engine_gpu_triton.py, PE/relaxation staging allocates many temporary tensors each call. For performance, preallocate staging buffers once per bucket size (or per max active) and reuse.
Avoid torch-side gathers in the hot path:
You currently do idx64 gathers into staging tensors. This is a big bandwidth + launch overhead tax. Prefer a Triton gather kernel that compacts/gathers SoA fields in one pass, or rely on your compaction step to produce already-packed SoA so you can operate on [0:n_active] contiguous ranges.
Bucketed CUDA graphs:
Your plan is correct: separate photon/electron graphs, capture micro-steps per bucket size. The next development step is to make the step function accept a fixed ‚Äúbucketed‚Äù active count and run exactly k micro-iterations per capture.
Software engineering / usability

Add pytest to requirements.txt (tests exist, but pytest isn‚Äôt installed right now).
Provide one runnable ‚Äútoy‚Äù entrypoint:
A minimal script that builds toy H5 tables, synthesizes a small CT/activity volume, runs TransportEngine, writes dose NIfTI. This becomes your ‚Äúgolden‚Äù smoke test and onboarding path.
Tighten configuration:
Either expand configs/example_simulation.yaml to match what pipeline.py expects, or change pipeline.py to accept the minimal config you currently provide.
Suggested next development roadmap (practical order)

Milestone 1: ‚ÄúRunnable MVP‚Äù
Fix missing returns/saves, reconcile missing modules/imports, complete example YAML, add a one-command smoke run.
Milestone 2: ‚ÄúPhysics baseline validation‚Äù
Photon-electron local water slab vs expected attenuation + energy deposition; then add Compton+PE; then add positrons+annihilation; then relaxation.
Milestone 3: ‚ÄúPerformance stabilization‚Äù
Eliminate hot-loop allocations/gathers, finalize compaction strategy, integrate bucketed CUDA graphs.
Milestone 4: ‚ÄúClinical realism‚Äù
HU‚Üímaterials with elemental compositions, better relaxation mapping, uncertainty outputs, and comparisons against Geant4/GATE for a reference phantom.
If you want, I can turn the ‚ÄúRunnable MVP‚Äù into concrete patches (fix return tables, save unc, reconcile imports, and expand the example config) so the package can execute an end-to-end toy run.

----------------------------------

resample using nibabel

from nibabel.processing import resample_from_to, resample_to_output

where 
    resample_from_to: Resample image from_img to mapped voxel space to_vox_map
    resample_to_output: Resample image in_img to output voxel axes (world space)

----------------------------------
What Changed

Added a simplified NEMA IEC body phantom generator in phantoms.py (make_nema_iec_body_phantom, optional sphere label volume).
Exported the new phantom helpers from __init__.py.
Added CLI generator script: make_nema_phantom.py.
Added generic ‚Äúrun pipeline on CT/activity NIfTI‚Äù script (for ICRP110-like inputs too): run_dosimetry_nifti.py.
Fixed missing uncertainty save in the pipeline: pipeline.py.
Added CPU-only test coverage for NEMA phantom sanity: test_milestone4_nema_phantom.py.
Updated Milestone 4 doc with these entrypoints: milestone_4.md.
How To Use

Generate NEMA phantom:
PYTHONPATH=src python [make_nema_phantom.py](http://_vscodecontentref_/8) --out_dir out_nema
Run dosimetry on NEMA or your ICRP110-like NIfTI volumes:
PYTHONPATH=src python [run_dosimetry_nifti.py](http://_vscodecontentref_/9) --ct <ct_hu.nii.gz> --activity <activity_bqs.nii.gz> --sim_yaml [example_simulation.yaml](http://_vscodecontentref_/10) --out_dose out_dose.nii.gz --out_unc out_unc.nii.gz
Validation

Ran pytest for the new and existing Milestone 4 CPU tests: all passed.

------------------------------------

MVP note: several modules are currently focused on unblocking an end-to-end run.
Transport physics will be upgraded in later milestones.

------------------------------------

What I found (and fixed)

The test suite was already clean: 13 passed, 10 skipped (skips are CUDA-gated).
The main physics-correctness issue relative to your PDF/CDF guidance was in source sampling: it was summing energies from multiple emission categories into a single photon/electron per history. That‚Äôs unphysical because interaction/transport depends nonlinearly on particle energy.
PDF/CDF fixes (aligned with docs/CDF_PDF_MC_suggestion.md)

Updated sampling.py to:
Use discrete CDF sampling for discrete lines (gamma/X/IE/Auger/alpha) with yield-weighted particle weights (total yield scales w).
Use inverse-CDF sampling for continuous beta spectra by integrating the tabulated PDF (trapezoid rule) and sampling via bucketize.
Avoid the old ‚Äúenergy summation across categories‚Äù shortcut.
Sample independent isotropic directions per particle category (photon/electron/positron).
Fixed an indentation regression in that file (docstring delimiter indentation) and verified it compiles and all tests still pass.
Make it pip-installable

Added pyproject.toml using a standard src layout with setuptools.
Verified editable install works: python -m pip install -e .
Verified imports work: import gpumcrpt; import gpumcrpt.pipeline
Validation

Re-ran pytest after changes: still 13 passed, 10 skipped.
If you want the next step per your CDF/PDF note: I can add an offline precompute step (CPU) that builds and caches per-nuclide discrete CDF/alias tables + beta CDF tables (so kernels only do O(1)/small-search sampling), instead of constructing CDFs on-the-fly during sampling.
------------------------------------
 scratch to remove the indentation corruption and restore a working module.
Implemented sampling_mode="accurate" (default): emits variable-length particle queues (multiple emissions per decay) instead of summing energies across categories.
Beta spectra are sampled via inverse-CDF from the tabulated PDF; discrete lines use yield-weighted sampling (discrete PDF ‚Üí CDF sampling).
Below-cutoff primaries deposit locally for energy conservation; alpha always deposits locally (expected value per decay).
Validation

python -m py_compile src/gpumcrpt/source/sampling.py passes.
pytest -q passes (exit code 0).
If you want, I can do the next accuracy pass you asked for on ‚Äútransport physics correctness‚Äù (beyond the source term): review where PDFs/CDFs are used in photon/electron interactions and relaxation, and identify/patch any places that are still using placeholders or non-invertible sampling.
------------------------------------